# ü§ñ Curso IA - Especializa√ß√£o IA Dev Eficiente

Um projeto de especializa√ß√£o em IA focado no desenvolvimento eficiente com IA, incluindo fundamentos de NLP, extra√ß√£o de documentos, embeddings, sistemas RAG (Retrieval-Augmented Generation) e an√°lise de documentos financeiros com busca h√≠brida.

## üìã Estrutura do Projeto

```
curso-ia/
‚îú‚îÄ‚îÄ fundamentos/                    # Conceitos fundamentais de NLP
‚îÇ   ‚îú‚îÄ‚îÄ tokenization-01.py             # Tokeniza√ß√£o b√°sica com NLTK
‚îÇ   ‚îú‚îÄ‚îÄ tokenization-02.py             # Tokeniza√ß√£o avan√ßada
‚îÇ   ‚îú‚îÄ‚îÄ tokenization-03.py             # An√°lise de frequ√™ncia de tokens
‚îÇ   ‚îî‚îÄ‚îÄ tokenization-04.py             # BM25 para busca por ranking
‚îÇ
‚îú‚îÄ‚îÄ docling/                        # Extra√ß√£o e processamento de documentos PDF
‚îÇ   ‚îú‚îÄ‚îÄ 1-extration.py                 # Extra√ß√£o b√°sica de documentos
‚îÇ   ‚îú‚îÄ‚îÄ 2-extraction-images.py         # Extra√ß√£o com imagens
‚îÇ   ‚îú‚îÄ‚îÄ 3-chunking.py                  # Divis√£o em chunks
‚îÇ   ‚îú‚îÄ‚îÄ 4-hybrid-chunker.py            # Chunking h√≠brido
‚îÇ   ‚îú‚îÄ‚îÄ 5-metadados.py                 # Extra√ß√£o de metadados com API
‚îÇ   ‚îú‚îÄ‚îÄ 6-embeddings.py                # Gera√ß√£o de embeddings
‚îÇ   ‚îî‚îÄ‚îÄ 2408.09869v5.pdf               # Documento de exemplo
‚îÇ
‚îú‚îÄ‚îÄ llm/                            # Integra√ß√£o com Large Language Models
‚îÇ   ‚îú‚îÄ‚îÄ llm-01.py                      # Utiliza√ß√£o da API Groq
‚îÇ   ‚îî‚îÄ‚îÄ llm-02.py                      # Intera√ß√µes avan√ßadas com LLMs
‚îÇ
‚îú‚îÄ‚îÄ rag/                            # Sistema de Retrieval-Augmented Generation
‚îÇ   ‚îú‚îÄ‚îÄ rag.py                         # RAG com busca vetorial
‚îÇ   ‚îî‚îÄ‚îÄ rag-qdrant.py                  # RAG usando Qdrant
‚îÇ
‚îú‚îÄ‚îÄ projeto/                        # An√°lise financeira com busca h√≠brida (Dense + Sparse + ColBERT)
‚îÇ   ‚îú‚îÄ‚îÄ create_collection.py           # Cria√ß√£o de cole√ß√£o Qdrant com vetores h√≠bridos
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py                   # Ingestion de filings SEC (10-K e 10-Q)
‚îÇ   ‚îú‚îÄ‚îÄ test-query.py                  # Query com busca h√≠brida e RRF fusion
‚îÇ   ‚îú‚îÄ‚îÄ app/                           # API FastAPI para processamento de eventos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Aplica√ß√£o principal FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py                  # Orquestrador de rotas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoint.py                # Implementa√ß√£o de endpoints
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edgar_client.py            # Cliente para fetching de EDGAR filings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic_chunker.py        # Chunking sem√¢ntico com HDBSCAN
‚îÇ   ‚îî‚îÄ‚îÄ AAPL_10-K_1A_temp.md           # An√°lise de Risk Factors - Apple
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml                  # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ .env                            # Vari√°veis de ambiente (n√£o commitar)
‚îî‚îÄ‚îÄ README.md                       # Este arquivo
```

## üöÄ Tecnologias Utilizadas

- **Processamento de Texto**: NLTK, Whoosh, BM25
- **Embeddings**: Sentence Transformers, FastEmbed, ColBERT
- **Extra√ß√£o de Documentos**: Docling (IBM)
- **LLMs**: Groq, OpenAI
- **Vector Database**: Qdrant (com busca h√≠brida)
- **Filings Financeiros**: EdgarTools (SEC EDGAR)
- **Clustering Sem√¢ntico**: HDBSCAN
- **Machine Learning**: Scikit-learn
- **Parsing Estruturado**: Pydantic
- **Linguagem**: Python 3.12+

## üì¶ Depend√™ncias Principais

O projeto utiliza as seguintes bibliotecas principais:

```
docling>=2.65.0                  # Extra√ß√£o de documentos PDF
edgartools>=5.6.4                # Acesso a SEC EDGAR filings
fastembed>=0.7.4                 # Embeddings r√°pidos (dense, sparse, ColBERT)
groq>=1.0.0                      # API Groq para LLMs
hdbscan>=0.8.41                  # Clustering sem√¢ntico
langextract>=1.1.1               # Extra√ß√£o de linguagem
nltk>=3.9.2                      # NLP
openai>=2.6.1                    # API OpenAI
python-dotenv>=1.2.1             # Gerenciamento de vari√°veis de ambiente
qdrant-client>=1.16.2            # Vector database com busca h√≠brida
rank-bm25>=0.2.2                 # Algoritmo BM25
sentence-transformers>=5.2.0     # Sentence embeddings
whoosh>=2.7.4                    # Full-text search
```

Veja [pyproject.toml](pyproject.toml) para a lista completa.

## üîß Instala√ß√£o

### Pr√©-requisitos
- Python 3.12 ou superior
- pip ou uv (gerenciador de pacotes)

### Passos

1. **Clone o reposit√≥rio**
```bash
git clone <repository-url>
cd curso-ia
```

2. **Crie e ative um ambiente virtual**

**Op√ß√£o A: Usando `uv` (recomendado)**
```bash
# Criar ambiente virtual com uv
uv venv

# Ativar ambiente virtual
source .venv/bin/activate  # macOS/Linux
# ou no Windows: .venv\Scripts\activate
```

**Op√ß√£o B: Usando Python nativo**
```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente virtual
source .venv/bin/activate  # macOS/Linux
# ou no Windows: .venv\Scripts\activate
```

3. **Instale as depend√™ncias**

**Com `uv` (mais r√°pido)**
```bash
uv sync
```

**Com pip**
```bash
pip install -e .
```

4. **Configure as vari√°veis de ambiente**
```bash
cp .env.example .env
# Edite .env com suas chaves de API
```

**Vari√°veis de ambiente necess√°rias:**
- `GROQ_API_KEY` - Chave da API Groq
- `OPENAI_API_KEY` - Chave da API OpenAI
- `GOOGLE_API_KEY` - Chave da API Google

### Verificar Ativa√ß√£o do Ambiente

```bash
# Se venv est√° ativado, voc√™ ver√° (.venv) no prompt
$ (.venv) python --version
Python 3.12.x

# Ou use
which python  # macOS/Linux
# deve apontar para: /path/to/projeto/.venv/bin/python
```

### Desativar Ambiente Virtual
```bash
deactivate
```

## üìö M√≥dulos Principais

### 1. **Fundamentos** (`fundamentos/`)
Introdu√ß√£o aos conceitos de NLP e processamento de texto:
- Tokeniza√ß√£o com NLTK
- An√°lise de frequ√™ncia
- Algoritmo BM25 para ranking de documentos

```bash
python fundamentos/tokenization-01.py
```

### 2. **Docling** (`docling/`)
Extra√ß√£o e processamento de documentos PDF usando a biblioteca Docling da IBM:
- Extra√ß√£o de texto e imagens
- Chunking inteligente
- Extra√ß√£o de metadados
- Gera√ß√£o de embeddings

```bash
python docling/1-extration.py
```

### 3. **LLM** (`llm/`)
Integra√ß√£o com modelos de linguagem:
- Utiliza√ß√£o da API Groq
- Chamadas e streaming
- Processamento de respostas

```bash
python llm/llm-01.py
```

### 4. **RAG** (`rag/`)
Sistema de Retrieval-Augmented Generation:
- Busca vetorial com embeddings
- Integra√ß√£o com Qdrant
- Recupera√ß√£o de contexto para LLMs

```bash
python rag/rag.py
python rag/rag-qdrant.py
```

### 5. **Projeto** (`projeto/`)
An√°lise de documentos financeiros da SEC com **busca h√≠brida** (Dense + Sparse + ColBERT):

#### Fluxo Completo:
1. **Fetching** de SEC 10-K e 10-Q filings com EdgarTools
2. **Chunking sem√¢ntico** usando HDBSCAN
3. **Embeddings h√≠bridos**:
   - **Dense**: `sentence-transformers/all-MiniLM-L6-v2` (384D)
   - **Sparse**: `Qdrant/bm25` (BM25 ranking)
   - **ColBERT**: `colbert-ir/colbertv2.0` (late interaction)
4. **Query com RRF Fusion** (Reciprocal Rank Fusion)

#### Scripts:
- `create_collection.py` - Cria cole√ß√£o Qdrant com vetores h√≠bridos
- `ingestion.py` - Faz download e ingest√£o de filings
- `test-query.py` - Testa queries com busca h√≠brida

```bash
# 1. Criar cole√ß√£o (precisa executar uma √∫nica vez)
python projeto/create_collection.py

# 2. Ingest√£o de dados
python projeto/ingestion.py

# 3. Testar queries
python projeto/test-query.py
```

#### Exemplo de Query com Busca H√≠brida:
```python
from projeto.utils.edgar_client import EdgarClient
from projeto.utils.semantic_chunker import SemanticChunker
from fastembed import TextEmbedding, SparseTextEmbedding, LateInteractionTextEmbedding
from qdrant_client import QdrantClient, models

# Query in English
query = "what are the main financial risks?"

# Gerar embeddings h√≠bridos
dense_embed = list(dense_model.query_embed([query]))[0].tolist()
sparse_embed = list(sparse_model.query_embed([query]))[0].as_object()
colbert_embed = list(colbert_model.query_embed([query]))[0].tolist()

# Buscar com Reciprocal Rank Fusion
results = qdrant.query_points(
    collection_name="financial",
    prefetch=[
        {
            "prefetch": [
                {"query": dense_embed, "using": "dense", "limit": 10},
                {"query": sparse_embed, "using": "sparse", "limit": 10},
            ],
            "query": models.FusionQuery(fusion=models.Fusion.RRF),
            "limit": 20,
        }
    ],
    query=colbert_embed,
    using="colbert",
    limit=3,
)
```

## üîê Configura√ß√£o de Chaves de API

O projeto utiliza vari√°veis de ambiente para gerenciar as chaves de API de forma segura. Crie um arquivo `.env` na raiz do projeto:

```bash
GROQ_API_KEY="sua_chave_aqui"
OPENAI_API_KEY="sua_chave_aqui"
GOOGLE_API_KEY="sua_chave_aqui"
QDRANT_URL="sua_url_aqui"
QDRANT_API_KEY="sua_chave_aqui"
```

**Vari√°veis de ambiente necess√°rias:**
- `GROQ_API_KEY` - Chave da API Groq
- `OPENAI_API_KEY` - Chave da API OpenAI
- `GOOGLE_API_KEY` - Chave da API Google
- `QDRANT_URL` - URL do servidor Qdrant
- `QDRANT_API_KEY` - Chave de autentica√ß√£o do Qdrant

**Nunca fa√ßa commit de arquivos `.env` com chaves reais!**

## üìñ Exemplos de Uso

### Tokeniza√ß√£o com BM25
```python
from rank_bm25 import BM25Okapi
import nltk

corpus = [
    "Este √© um exemplo de documento",
    "Outro documento para teste",
    "Terceiro documento aqui"
]

tokenized_corpus = [doc.split() for doc in corpus]
bm25 = BM25Okapi(tokenized_corpus)

query = "example document"
scores = bm25.get_scores(query.split())
```

### Extra√ß√£o de Documentos PDF com Metadados
```python
import os
from dotenv import load_dotenv
import langextract as lx
from docling.document_converter import DocumentConverter

load_dotenv()

converter = DocumentConverter()
result = converter.convert("documento.pdf")
markdown = result.document.export_to_markdown()

# Extrair metadados usando Gemini
extraction_result = lx.extract(
    text_or_documents=markdown[:4000],
    prompt_description="Extraia t√≠tulo, autores, afilia√ß√£o e URLs de reposit√≥rio",
    model_id="gemini-2.5-flash",
    api_key=os.getenv("GOOGLE_API_KEY"),
)
```

### RAG com Qdrant (busca simples)
```python
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

client = QdrantClient(
    url="https://seu-url-qdrant.io",
    api_key="sua-api-key"
)
model = SentenceTransformer("all-MiniLM-L6-v2")

# Gerar embedding e buscar
query_embedding = model.encode("what is the subject of this document?")
results = client.search(
    collection_name="documents",
    query_vector=query_embedding,
    limit=5
)
```

### Chunking Sem√¢ntico com HDBSCAN
```python
from projeto.utils.semantic_chunker import SemanticChunker

chunker = SemanticChunker(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    min_cluster_size=3,
    max_tokens=300
)

text = "Your text here..."
chunks = chunker.create_chunks(text)
print(f"Criados {len(chunks)} chunks sem√¢nticos")
```

### Fetching de EDGAR com EdgarTools
```python
from projeto.utils.edgar_client import EdgarClient

client = EdgarClient(email="seu_email@example.com")

# Fetch 10-K filing
data_10k = client.fetch_filing_data("AAPL", "10-K")
text_10k = client.get_combined_text(data_10k)

# Metadados extra√≠dos
print(f"Empresa: {data_10k['metadata']['company_name']}")
print(f"Data: {data_10k['metadata']['report_date']}")
```

## üéØ Fluxo de Uso Completo - Projeto Financeiro

### 1. **Setup Inicial**
```bash
# Instalar depend√™ncias
uv install

# Configurar vari√°veis de ambiente
cp .env.example .env
# Editar .env com suas chaves
```

### 2. **Criar Cole√ß√£o Qdrant**
```bash
python projeto/create_collection.py
```
Cria uma cole√ß√£o com esquema de vetores h√≠bridos:
- `dense`: 384 dimens√µes (all-MiniLM-L6-v2)
- `sparse`: BM25 vectors
- `colbert`: 128 dimens√µes com MultiVectorConfig

### 3. **Ingest√£o de Dados**
```bash
python projeto/ingestion.py
```
Processa:
- 10-K filing (relat√≥rio anual)
- 10-Q filing (relat√≥rio trimestral)
- Extrai itens relevantes (Risk Factors, MD&A, etc)
- Faz chunking sem√¢ntico
- Gera embeddings h√≠bridos
- Upload para Qdrant

### 4. **Query com Busca H√≠brida**
```bash
python projeto/test-query.py
```
Demonstra busca com RRF Fusion:
- Dense similarity search
- Sparse BM25 search
- ColBERT late interaction
- Combina√ß√£o com Reciprocal Rank Fusion

### 5. **API FastAPI para Processamento de Eventos**
```bash
cd projeto/app
uv run uvicorn main:app --reload --port 8001
```

Acesse:
- **API**: http://127.0.0.1:8001/events/
- **Documenta√ß√£o**: http://127.0.0.1:8001/docs (Swagger UI)
- **ReDoc**: http://127.0.0.1:8001/redoc

#### Exemplo de cURL
```bash
curl -X POST http://127.0.0.1:8001/events/ \
  -H "Content-Type: application/json" \
  -d '{"event_id":"123","event_type":"user_signup","event_data":{"name":"Jo√£o"}}'
```

#### Arquitetura da API
```
main.py (entrada)
    ‚Üì
    ‚îî‚îÄ‚Üí app = FastAPI()
        app.include_router(process_router)
            ‚Üì
        router.py (orquestrador)
            ‚Üì
            ‚îî‚îÄ‚Üí router.include_router(endpoint.router, prefix="/events")
                ‚Üì
            endpoint.py (implementa√ß√£o)
                ‚Üì
                ‚îî‚îÄ‚Üí POST /events/ ‚Üí handle_event()
```

**Estrutura de Arquivos:**
- `main.py`: Aplica√ß√£o principal, registra routers
- `router.py`: Orquestra rotas, agrupa endpoints
- `endpoint.py`: Define schemas (Pydantic) e implementa endpoints

## ÔøΩ Conceitos Principais

### Busca H√≠brida (Dense + Sparse + ColBERT)

A busca h√≠brida combina m√∫ltiplas estrat√©gias para melhor relev√¢ncia:

| Tipo | Modelo | Dimens√µes | Vantagem |
|------|--------|-----------|----------|
| **Dense** | all-MiniLM-L6-v2 | 384D | Captura sem√¢ntica geral |
| **Sparse** | BM25 | Vari√°vel | Busca por palavras-chave exatas |
| **ColBERT** | colbertv2.0 | 128D (multi) | Late interaction, melhor precis√£o |

**RRF (Reciprocal Rank Fusion)**: Combina rankings de m√∫ltiplas buscas para resultado final.

### Chunking Sem√¢ntico com HDBSCAN

Em vez de chunks de tamanho fixo:
1. Divide texto em par√°grafos
2. Gera embeddings dos par√°grafos
3. Usa HDBSCAN para encontrar clusters sem√¢nticos
4. Combina par√°grafos do mesmo cluster
5. Respeita limite de tokens (max_tokens)

Resultado: chunks que mant√™m coer√™ncia sem√¢ntica!

### EdgarTools para SEC EDGAR

Acessa automaticamente:
- **10-K**: Relat√≥rio anual completo
- **10-Q**: Relat√≥rio trimestral
- **Extrai**: Item 1 (Neg√≥cio), Item 1A (Risk Factors), Item 7 (MD&A), etc.

```python
data = client.fetch_filing_data("AAPL", "10-K")
# Retorna: metadata + items estruturados
```

---

## üìù Licen√ßa

Este projeto √© parte de um curso de especializa√ß√£o em IA. Verifique a licen√ßa espec√≠fica do curso antes de usar em produ√ß√£o.

## üë§ Autor

Desenvolvido durante o curso de Especializa√ß√£o em IA Dev Eficiente.

## üìû Suporte e Refer√™ncias

Para d√∫vidas e suporte, verifique a documenta√ß√£o das bibliotecas utilizadas:

- [Docling Documentation](https://ds4sd.github.io/docling/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [FastEmbed (Dense, Sparse, ColBERT)](https://github.com/qdrant/fastembed)
- [EdgarTools Documentation](https://github.com/dgunning/edgartools)
- [Sentence Transformers](https://www.sbert.net/)
- [NLTK Book](https://www.nltk.org/book/)
- [HDBSCAN](https://hdbscan.readthedocs.io/)
- [Groq API](https://groq.com/)

---

**√öltima atualiza√ß√£o**: Dezembro de 2025
