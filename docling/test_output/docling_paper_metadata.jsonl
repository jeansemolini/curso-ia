{"extractions": [{"extraction_class": "title", "extraction_text": "Docling Technical Report", "char_interval": {"start_pos": 19, "end_pos": 43}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Christoph Auer", "char_interval": {"start_pos": 61, "end_pos": 75}, "alignment_status": "match_exact", "extraction_index": 2, "group_index": 1, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Maksym Lysak", "char_interval": {"start_pos": 76, "end_pos": 88}, "alignment_status": "match_exact", "extraction_index": 3, "group_index": 2, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Ahmed Nassar", "char_interval": {"start_pos": 89, "end_pos": 101}, "alignment_status": "match_exact", "extraction_index": 4, "group_index": 3, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Michele Dolfi", "char_interval": {"start_pos": 102, "end_pos": 115}, "alignment_status": "match_exact", "extraction_index": 5, "group_index": 4, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Nikolaos Livathinos", "char_interval": {"start_pos": 116, "end_pos": 135}, "alignment_status": "match_exact", "extraction_index": 6, "group_index": 5, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Panos Vagenas", "char_interval": {"start_pos": 136, "end_pos": 149}, "alignment_status": "match_exact", "extraction_index": 7, "group_index": 6, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Cesar Berrospi Ramis", "char_interval": {"start_pos": 150, "end_pos": 170}, "alignment_status": "match_exact", "extraction_index": 8, "group_index": 7, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Matteo Omenetti", "char_interval": {"start_pos": 171, "end_pos": 186}, "alignment_status": "match_exact", "extraction_index": 9, "group_index": 8, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Fabian Lindlbauer", "char_interval": {"start_pos": 187, "end_pos": 204}, "alignment_status": "match_exact", "extraction_index": 10, "group_index": 9, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Kasper Dinkla", "char_interval": {"start_pos": 205, "end_pos": 218}, "alignment_status": "match_exact", "extraction_index": 11, "group_index": 10, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Lokesh Mishra", "char_interval": {"start_pos": 219, "end_pos": 232}, "alignment_status": "match_exact", "extraction_index": 12, "group_index": 11, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Yusik Kim", "char_interval": {"start_pos": 233, "end_pos": 242}, "alignment_status": "match_exact", "extraction_index": 13, "group_index": 12, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Shubham Gupta", "char_interval": {"start_pos": 243, "end_pos": 256}, "alignment_status": "match_exact", "extraction_index": 14, "group_index": 13, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Rafael Teixeira de Lima", "char_interval": {"start_pos": 257, "end_pos": 280}, "alignment_status": "match_exact", "extraction_index": 15, "group_index": 14, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Valery Weber", "char_interval": {"start_pos": 281, "end_pos": 293}, "alignment_status": "match_exact", "extraction_index": 16, "group_index": 15, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Lucas Morin", "char_interval": {"start_pos": 294, "end_pos": 305}, "alignment_status": "match_exact", "extraction_index": 17, "group_index": 16, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Ingmar Meijer", "char_interval": {"start_pos": 306, "end_pos": 319}, "alignment_status": "match_exact", "extraction_index": 18, "group_index": 17, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Viktor Kuropiatnyk", "char_interval": {"start_pos": 320, "end_pos": 338}, "alignment_status": "match_exact", "extraction_index": 19, "group_index": 18, "description": null, "attributes": null}, {"extraction_class": "author", "extraction_text": "Peter W. J. Staar", "char_interval": {"start_pos": 339, "end_pos": 356}, "alignment_status": "match_exact", "extraction_index": 20, "group_index": 19, "description": null, "attributes": null}, {"extraction_class": "affiliation", "extraction_text": "AI4K Group, IBM Research R¨ uschlikon, Switzerland", "char_interval": {"start_pos": 358, "end_pos": 408}, "alignment_status": "match_exact", "extraction_index": 21, "group_index": 20, "description": null, "attributes": null}, {"extraction_class": "url", "extraction_text": "github.com/DS4SD/docling", "char_interval": {"start_pos": 2887, "end_pos": 2911}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": {"type": "repository"}}, {"extraction_class": "title", "extraction_text": "DocLayNet: A Large Human -Annotated Dataset for Document -Layout Analysis", "char_interval": {"start_pos": 3692, "end_pos": 3765}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": {}}], "text": "<!-- image -->\n\n## Docling Technical Report\n\n## Version 1.0\n\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n\nAI4K Group, IBM Research R¨ uschlikon, Switzerland\n\n## Abstract\n\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n\n## 1 Introduction\n\nConverting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\n\nHere is what Docling delivers today:\n\n- Converts PDF documents to JSON or Markdown format, stable and lightning fast\n- Understands detailed page layout, reading order, locates figures and recovers table structures\n- Extracts metadata from the document, such as title, authors, references and language\n- Optionally applies OCR, e.g. for scanned PDFs\n- Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\n- Can leverage different accelerators (GPU, MPS, etc).\n\n## 2 Getting Started\n\nTo use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\n\nDocling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\n\nfrom docling.document\\_converter import DocumentConverter\n\n```\nsource = \"https://arxiv.org/pdf/2206.01062\" # PDF path or URL converter = DocumentConverter() result = converter.convert_single(source) print(result.render_as_markdown()) # output: \"## DocLayNet: A Large Human -Annotated Dataset for Document -Layout Analysis [...]\"\n```\n\nOptionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget o", "document_id": "doc_f8baa723"}
